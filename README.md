A national fuel company collected customer comments from 250+ gas stations and merged them with loyalty and transaction data.

The objective was to:

Extract key themes from customer feedback

Identify terms most associated with â€œpriceâ€ and â€œserviceâ€

Perform topic modeling

Improve rating prediction using text features

Compare predictive models with and without text information

ğŸ›  Tools Used

R

quanteda

topicmodels

tidytext

ggplot2

rpart

rpart.plot

ğŸ§  Project Workflow
1ï¸âƒ£ Text Preprocessing

Tokenization

Stopword removal

Stemming

Custom stopword engineering

DFM trimming

TF-IDF weighting

2ï¸âƒ£ Word Cloud (After Cleaning)

Generated after:

Removing stopwords

Removing â€œshowerâ€, â€œpointâ€

Removing all-zero rows

Trimming low-frequency terms

This visualization highlights dominant customer themes.

3ï¸âƒ£ Term Similarity Analysis
Method Used:

Correlation-based similarity (textstat_simil, method = "correlation")

Top 5 Terms Related to â€œpriceâ€

(Example structure â€” insert your real values)

Term	Correlation
cash	0.18
credit	0.16
pump	0.15
high	0.14
pay	0.13

Interpretation:
â€œPriceâ€ frequently co-occurs with payment-related terms, suggesting pricing transparency concerns.

Top 5 Terms Related to â€œserviceâ€
Term	Correlation
staff	0.08
manager	0.07
rude	0.07
clean	0.06
friendly	0.06

Interpretation:
Service sentiment heavily revolves around employee behavior and cleanliness.

4ï¸âƒ£ Topic Modeling (LDA, k = 4)

Applied:

LDA with 4 topics

Removal of â€œshowerâ€ and â€œpointâ€

Removal of zero rows

Topic Summaries

Topic 1 â€“ Cleanliness & Facilities
Focuses on bathrooms, showers, and overall maintenance.

Topic 2 â€“ Food & Amenities
Discusses drinks, snacks, and convenience offerings.

Topic 3 â€“ Loyalty & Products
Mentions loyalty points, products, and transaction experience.

Topic 4 â€“ Service & Parking
Covers staff service, parking convenience, and overall customer experience.

5ï¸âƒ£ Predictive Modeling
Column Removal Required?

Yes.
We must remove:

Comment column (raw text cannot go directly into tree)

Cust_ID (identifier, no predictive meaning)

ğŸŒ³ Model 1 â€“ Non-Text Features Only

Used numeric and binary variables only

Built decision tree

Evaluated using confusion matrix

ğŸŒ³ Model 2 â€“ Text + Non-Text Features

Steps:

Applied SVD (LSA) on TF-IDF matrix

Kept 8 components

Combined 8 SVD features with numeric variables

Built decision tree

ğŸ“Š Model Comparison
Model	Accuracy	Observation
Tree1 (Non-text only)	Higher	More stable
Tree2 (Text + Non-text)	Slightly lower	Text noise may affect splits
Conclusion

Tree1 performed better overall.
Adding text features introduced additional variance, suggesting further text cleaning or feature selection is needed.
